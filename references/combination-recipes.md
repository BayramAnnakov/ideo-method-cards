# Combination Recipes: Pre-Designed Method Sequences

Curated sequences of IDEO's 51 Design Method Cards for common design research scenarios. Each recipe orders methods logically: observe before analyze, analyze before ideate.

---

## 1. Understand Before Building

**Duration**: 4 hours (half-day) | **Team Size**: 3-5 | **Format**: In-person or Hybrid

### Goal

Build genuine empathy and understanding of user context before any solution work begins. Ideal for kicking off a new feature or product initiative where the team needs shared grounding in real user behavior and needs before writing a single line of code or sketching a wireframe.

### Method Sequence

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 0:00-0:30 | Fly on the Wall | LOOK | Silently observe users in their natural environment to capture unfiltered behavior |
| 0:30-1:00 | Narration | ASK | Have users narrate their process aloud to surface hidden reasoning |
| 1:00-1:30 | Draw the Experience | ASK | Ask participants to sketch their experience to surface emotions and unspoken perceptions |
| 1:30-2:00 | Cognitive Maps | ASK | Ask participants to draw how they mentally organize the problem space |
| 2:00-2:30 | Card Sort | ASK | Understand how users categorize and prioritize concepts |
| 2:30-3:00 | Flow Analysis | LEARN | Map the sequence of actions, decisions, and handoffs in current workflows |
| 3:00-3:30 | Affinity Diagrams | LEARN | Cluster all observations into emergent themes as a team |
| 3:30-4:00 | Character Profiles | LEARN | Synthesize findings into 2-3 research-grounded character narratives to carry forward |

### Expected Outputs

- 2-3 draft character profiles grounded in observation
- Affinity diagram of clustered insights (photo-documented)
- Flow diagram of current user workflow
- Prioritized list of user pain points and unmet needs

### Tips

- Keep the first hour purely observational; resist jumping to solutions
- Assign a dedicated note-taker for each observation method
- Use the Cognitive Maps output to challenge internal assumptions about how users think

---

## 2. Rapid Problem Discovery

**Duration**: 2.5 hours | **Team Size**: 2-4 | **Format**: In-person or Remote

### Goal

Quickly surface core user problems when time is extremely limited. Useful for sprint planning, quick pivots, or when a team needs just enough user insight to make a confident directional decision without a multi-day research effort.

### Method Sequence

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 0:00-0:30 | Extreme User Interviews | ASK | Talk to power users and non-users to find the sharpest pain points fast |
| 0:30-1:00 | Surveys & Questionnaires | ASK | Collect broad quantitative signal to complement the qualitative extremes |
| 1:00-1:20 | Five Whys | ASK | Drill into the top 2-3 problems to find root causes |
| 1:20-1:40 | Affinity Diagrams | LEARN | Rapidly cluster findings into actionable problem themes |
| 1:40-2:10 | Collage | ASK | Create quick visual representations of the problem space to align the team |
| 2:10-2:30 | Word-Concept Association | ASK | Rapid association exercise to validate problem framing and emotional resonance |

### Expected Outputs

- Top 3-5 validated problem statements with root cause analysis
- Affinity cluster of raw user feedback
- Visual collage capturing the emotional dimension of the problem
- Ranked priority list for next steps

### Tips

- Pre-recruit extreme users before the session to avoid wasting time on logistics
- Use digital whiteboards (Miro, FigJam) for remote Affinity Diagrams
- Timebox Five Whys strictly; it is easy to spiral into philosophical territory

---

## 3. Full Discovery Sprint

**Duration**: 3 days | **Team Size**: 3-6 | **Format**: In-person preferred, Hybrid possible

### Goal

Conduct a comprehensive research sprint when entering a new product or feature area. Covers the full arc from field observation through synthesis to early concept validation, giving the team deep user understanding and testable direction in under a week.

### Method Sequence

**Day 1: Immerse and Observe**

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 9:00-10:00 | Shadowing | LOOK | Follow a user through their activities for deep contextual immersion |
| 10:00-11:00 | Behavioral Archaeology | LOOK | Study physical/digital artifacts users leave behind for unspoken patterns |
| 11:00-12:00 | Guided Tours | LOOK | Have users walk you through their environment and tools |
| 13:00-14:00 | Narration | ASK | Have users narrate their thought process aloud as they perform key tasks |
| 14:00-15:00 | Extreme User Interviews | ASK | Interview users at the extremes of the target audience to amplify latent needs |
| 15:00-16:00 | Draw the Experience | ASK | Ask participants to sketch their experience to surface emotions and perceptions |

**Day 2: Analyze and Synthesize**

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 9:00-10:00 | Character Profiles | LEARN | Build detailed research-grounded character narratives from Day 1 observations |
| 10:00-11:00 | Cognitive Maps | ASK | Map mental models and decision frameworks users employ |
| 11:00-12:00 | Flow Analysis | LEARN | Document end-to-end workflows with pain points highlighted |
| 13:00-14:00 | Affinity Diagrams | LEARN | Cluster all Day 1 data into themes |
| 14:00-15:00 | Activity Analysis | LEARN | Break down key tasks into component activities and identify friction |
| 15:00-16:00 | Error Analysis | LEARN | Review patterns from Day 1 to catalog failure modes and workarounds |

**Day 3: Ideate and Validate**

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 9:00-10:00 | Predict Next Year's Headlines | TRY | Envision bold outcomes and align on aspirational goals before generating solutions |
| 10:00-11:30 | Bodystorming | TRY | Physically act out concepts to find ergonomic and experiential issues |
| 11:30-12:30 | Scenarios | TRY | Write narrative use-case scenarios for the top 3 concepts |
| 13:30-14:30 | Paper Prototyping | TRY | Build quick low-fidelity prototypes of leading concepts |
| 14:30-16:00 | Quick-and-Dirty Prototyping | TRY | Test prototypes with 3-5 users for immediate directional feedback |

### Expected Outputs

- Research-backed character profile set (3-4 profiles)
- Annotated workflow maps with pain points
- Affinity diagram of clustered insights
- 2-3 validated concept directions with early user feedback
- Photo/video documentation of all sessions

### Tips

- Debrief as a team at the end of each day; do not let raw notes pile up
- Recruit 6-8 participants across the three days for diversity
- Day 3 prototypes should be intentionally rough to invite honest feedback

---

## 4. Remote Research Sprint

**Duration**: 2 days | **Team Size**: 2-5 | **Format**: Fully Remote

### Goal

Run meaningful, structured design research when in-person observation is not possible. Leverages methods that translate well to video calls, digital tools, and asynchronous participation.

### Method Sequence

**Day 1: Remote Observation and Inquiry**

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 9:00-10:00 | Surveys & Questionnaires | ASK | Deploy a targeted survey to a broader participant pool (distributed the night before) |
| 10:00-11:00 | Narration | ASK | Users share screen and narrate their workflow via video call |
| 11:00-12:00 | Extreme User Interviews | ASK | Interview power users and novices via video call to surface sharp pain points |
| 13:00-14:00 | Card Sort | ASK | Run a digital card sort (OptimalSort or similar) to map mental models |
| 14:00-15:00 | Draw the Experience | ASK | Participants sketch and share their experience drawings via screen share |

**Day 2: Synthesis and Early Concepts**

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 9:00-10:00 | Affinity Diagrams | LEARN | Cluster findings on a shared digital whiteboard |
| 10:00-11:00 | Cognitive Maps | ASK | Synthesize mental models from Day 1 data |
| 11:00-12:00 | Character Profiles | LEARN | Build research-grounded character narratives collaboratively in shared docs |
| 13:00-14:00 | Scenarios | TRY | Write scenarios describing how characters would experience proposed solutions |
| 14:00-15:00 | Collage | ASK | Create mood boards / visual collages for concept directions using shared tools |

### Expected Outputs

- Digital affinity diagram with linked source data
- 2-3 character profiles with supporting evidence
- Scenario narratives for top concept directions
- Survey results summary with quantitative insights
- Shared Miro/FigJam board as living research artifact

### Tips

- Send survey instructions 24 hours before Day 1 so data arrives ready for synthesis
- Use breakout rooms for parallel interview sessions
- Record all video sessions (with consent) for team members who cannot attend live
- Digital Card Sort tools provide built-in analysis; leverage that to save synthesis time

---

## 5. Solo Researcher Kit

**Duration**: 1 week (async, ~3 hours/day) | **Team Size**: 1 | **Format**: Remote or In-person

### Goal

Enable a single researcher to conduct meaningful design research without a team. Methods are chosen for solo feasibility and staggered across the week to allow for asynchronous data collection and reflection between sessions.

### Method Sequence

| Day | Method | Category | Purpose |
|-----|--------|----------|---------|
| Mon AM | Fly on the Wall | LOOK | Spend time silently observing users in their context |
| Mon PM | Surveys & Questionnaires | ASK | Launch a short survey to a broader audience for quantitative context |
| Tue AM | Extreme User Interviews | ASK | Interview 2 extreme users (power user + reluctant user), 45 min each |
| Tue PM | Five Whys | ASK | Analyze interview transcripts using Five Whys for root causes |
| Wed AM | Narration | ASK | Have a user narrate their workflow aloud during a 30-60 min session |
| Wed PM | Affinity Diagrams | LEARN | Solo affinity clustering of all data collected so far |
| Thu AM | Character Profiles | LEARN | Build detailed character profiles from clustered data |
| Thu PM | Scenarios | TRY | Write 3-4 scenario narratives for emerging directions |
| Fri AM | Paper Prototyping | TRY | Sketch low-fidelity prototypes based on scenarios |
| Fri PM | Error Analysis | LEARN | Review prototypes critically for failure modes and gaps |

### Expected Outputs

- Personal research journal with daily reflections
- 2-3 character profiles grounded in observation and interview data
- Affinity diagram (photo or digital)
- Scenario narratives and paper prototype sketches
- Error analysis document identifying risks in proposed directions

### Tips

- Protect your analysis time; it is tempting to schedule back-to-back sessions
- Use voice memos during Fly on the Wall to capture observations hands-free
- Digital tools (Notion, Miro) help a solo researcher maintain structure
- Schedule a stakeholder share-out for the following Monday to create accountability

---

## 6. Stakeholder Alignment

**Duration**: 3.5 hours | **Team Size**: 5-12 (cross-functional) | **Format**: In-person preferred

### Goal

Get stakeholders from different functions (product, engineering, design, business) onto the same page about user needs, shared vocabulary, and research priorities. Best used before a major initiative to prevent misalignment downstream.

### Method Sequence

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 0:00-0:30 | Fly on the Wall | LOOK | Stakeholders silently observe real user sessions together to build shared empathy |
| 0:30-1:00 | Narration | ASK | Watch a user narrate their experience; stakeholders note surprises |
| 1:00-2:00 | Un-focus Group | ASK | Facilitated discussion with diverse stakeholders reacting to what they observed |
| 2:00-2:30 | Card Sort | ASK | Stakeholders collaboratively sort user needs by priority and feasibility |
| 2:30-3:00 | Cognitive Maps | ASK | Each stakeholder draws their mental model of the user; compare for gaps |
| 3:00-3:30 | Collage | ASK | Collaboratively build a visual representation of aligned understanding |

### Expected Outputs

- Shared priority ranking of user needs
- Side-by-side cognitive maps revealing assumption gaps across functions
- Photo-documented collage representing team alignment
- List of open questions requiring further research
- Agreed-upon next steps and owners

### Tips

- Keep the Fly on the Wall session live if possible; pre-recorded video is a fallback
- The Cognitive Maps comparison is often the most eye-opening moment; allocate extra time if discussion is rich
- Have a neutral facilitator so no single function dominates the Card Sort
- Capture explicit commitments at the end; alignment without action items fades quickly

---

## 7. Competitive Intelligence Deep Dive

**Duration**: 1 day (8 hours) | **Team Size**: 2-4 | **Format**: Remote or In-person

### Goal

Develop a deep, user-centered understanding of the competitive landscape. Goes beyond feature comparison to understand how competitors shape user expectations, mental models, and behavior patterns.

### Method Sequence

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 9:00-10:00 | Behavioral Archaeology | LOOK | Study artifacts competitors leave behind: onboarding flows, emails, UI patterns |
| 10:00-11:00 | Long-Range Forecasts | LEARN | Research market trends and technology shifts affecting the competitive landscape |
| 11:00-12:00 | Competitive Product Survey | LEARN | Systematically map features, pricing, positioning across competitors |
| 13:00-14:00 | Extreme User Interviews | ASK | Interview users who switched to/from competitors to understand decision drivers |
| 14:00-15:00 | Card Sort | ASK | Have users sort competitor features by value to reveal what actually matters |
| 15:00-16:00 | Flow Analysis | LEARN | Map and compare key user flows across top 3 competitors |
| 16:00-17:00 | Scenarios | TRY | Write scenarios describing how your product could differentiate based on findings |

### Expected Outputs

- Competitive landscape map with user-centered positioning
- Feature value matrix (what users actually value vs. what competitors offer)
- Flow comparison diagrams for 2-3 key workflows
- Trend analysis with 6-12 month outlook
- 3-5 differentiation scenarios grounded in user needs

### Tips

- Avoid feature-for-feature comparison tunnel vision; focus on user outcomes
- Interview users of competing products, not just your own users
- Behavioral Archaeology of competitor onboarding reveals their assumptions about users
- Pair quantitative survey data with qualitative interview insights for a complete picture

---

## 8. Accessibility Audit

**Duration**: 4.5 hours (half-day) | **Team Size**: 2-4 | **Format**: In-person or Hybrid

### Goal

Evaluate product accessibility through user-centered research methods rather than purely automated tooling. Surfaces usability barriers for people with diverse abilities and generates actionable design improvements.

### Method Sequence

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 0:00-0:40 | Guided Tours | LOOK | Users with diverse abilities walk through the product, narrating barriers |
| 0:40-1:25 | Extreme User Interviews | ASK | Interview users with diverse abilities about their assistive technology and adaptation strategies |
| 1:25-1:55 | Narration | ASK | Users narrate their thought process while attempting key tasks with assistive tools |
| 1:55-2:25 | Error Analysis | LEARN | Catalog points where the product fails or confuses users with accessibility needs |
| 2:25-2:55 | Activity Analysis | LEARN | Break down key tasks into steps and identify where accessibility breaks down |
| 2:55-3:25 | Flow Analysis | LEARN | Map end-to-end flows, annotating accessibility barriers at each step |
| 3:25-4:05 | Affinity Diagrams | LEARN | Cluster all accessibility barriers by type, severity, and affected user groups |
| 4:05-4:30 | Scenarios | TRY | Write inclusive design scenarios addressing the most critical barriers |

### Expected Outputs

- Prioritized accessibility barrier inventory (by severity and frequency)
- Annotated flow diagrams showing barrier locations
- Inclusive design scenarios for top 5 barriers
- Recommendations mapped to WCAG guidelines where applicable
- Photo/video documentation of user sessions (with consent)

### Tips

- Recruit participants with a range of abilities: visual, motor, cognitive, auditory
- Pair automated accessibility scans (Axe, Lighthouse) with these human-centered methods
- Error Analysis is especially powerful here; it reveals failures no automated tool catches
- Prioritize barriers that block task completion over cosmetic issues

---

## 9. Pre-Launch Validation

**Duration**: 2 days | **Team Size**: 3-5 | **Format**: Hybrid

### Goal

Validate critical assumptions before shipping a product or major feature. Combines rapid prototyping with structured user testing to identify show-stopping issues while there is still time to address them.

### Method Sequence

**Day 1: Prototype and Prepare**

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 9:00-10:00 | Scenarios | TRY | Write key usage scenarios that must work for launch to succeed |
| 10:00-11:30 | Rapid Ethnography | LOOK | Quick field observation to reality-check assumptions in the current build |
| 11:30-12:30 | Error Analysis | LEARN | Team walkthrough of the product to predict failure modes |
| 13:30-15:00 | Paper Prototyping | TRY | Build prototypes for any flows that need redesign based on morning findings |
| 15:00-16:30 | Predict Next Year's Headlines | TRY | Imagine best-case and worst-case launch outcomes to surface hidden risks |

**Day 2: Test and Validate**

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 9:00-10:30 | Quick-and-Dirty Prototyping | TRY | Refine prototypes based on Day 1 error analysis |
| 10:30-12:00 | Try It Yourself | TRY | Team members use the product end-to-end as if they were real users |
| 13:00-14:00 | Extreme User Interviews | ASK | Test with power users and novices to find edge-case failures |
| 14:00-15:00 | Surveys & Questionnaires | ASK | Collect structured usability ratings from test participants |
| 15:00-16:00 | Affinity Diagrams | LEARN | Cluster all findings into launch-blocking vs. post-launch issues |

### Expected Outputs

- Launch readiness assessment: go/no-go recommendation with evidence
- Prioritized issue list (launch-blocking vs. post-launch backlog)
- Validated scenarios with pass/fail status
- Usability scores from structured survey
- Risk register based on Predict Next Year's Headlines exercise

### Tips

- Be brutally honest during Error Analysis; the goal is to find problems, not confirm the launch
- Try It Yourself works best when team members use unfamiliar devices or browsers
- Recruit 5-8 external users for Day 2 testing; internal users are too forgiving
- Separate findings into "must fix before launch" and "fast follow" to avoid scope creep

---

## 10. Team Onboarding to User Research

**Duration**: 4 hours (half-day) | **Team Size**: 6-15 | **Format**: In-person

### Goal

Introduce a team that is new to design research to the practice through hands-on methods. Builds research muscle memory through doing rather than lecturing. Participants leave with practical skills they can apply independently.

### Method Sequence

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 0:00-0:15 | (Introduction) | -- | Brief framing: why user research matters, overview of the four categories |
| 0:15-0:45 | Fly on the Wall | LOOK | Participants practice silent observation (use video if live users are not available) |
| 0:45-1:15 | Five Whys | ASK | Pairs practice drilling into root causes on a sample problem |
| 1:15-1:45 | Card Sort | ASK | Teams run a mini card sort to experience structured analysis |
| 1:45-2:15 | Affinity Diagrams | LEARN | Teams cluster their combined observations to practice synthesis |
| 2:15-2:30 | (Break) | -- | -- |
| 2:30-3:00 | Bodystorming | TRY | Physical, energetic activity to demonstrate experiential ideation |
| 3:00-3:30 | Paper Prototyping | TRY | Quick sketching exercise to connect research to design |
| 3:30-4:00 | (Retrospective) | -- | Reflect on which methods felt most valuable; plan for real application |

### Expected Outputs

- Team familiarity with LOOK, LEARN, ASK, and TRY categories
- Practice artifacts from each method (observation notes, card sort results, affinity diagram, sketches)
- Individual action plans: each participant picks one method to apply in the next two weeks
- Shared glossary of research terms and methods

### Tips

- Use a real (not hypothetical) product challenge for exercises; learning sticks better
- Pair experienced researchers with novices for the observation exercise
- Bodystorming is intentionally physical and fun; it breaks the "research is boring" misconception
- Provide a one-page method reference card for participants to take away

---

## 11. Concept Stress Test

**Duration**: 3 hours | **Team Size**: 4-8 | **Format**: In-person or Hybrid

### Goal

Take an existing concept or early prototype and stress-test it from multiple angles before committing development resources. Deliberately seeks out weaknesses, edge cases, and unexamined assumptions.

### Method Sequence

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 0:00-0:30 | Scenarios | TRY | Write best-case, worst-case, and edge-case usage scenarios |
| 0:30-1:00 | Error Analysis | LEARN | Systematically walk through the concept identifying potential failure points |
| 1:00-1:45 | Extreme User Interviews | ASK | Test the concept with users at the extremes of the target audience |
| 1:45-2:15 | Bodystorming | TRY | Physically act out key scenarios to find ergonomic and experiential issues |
| 2:15-2:45 | Predict Next Year's Headlines | TRY | Imagine media coverage of the concept to surface reputation and ethical risks |
| 2:45-3:00 | Affinity Diagrams | LEARN | Cluster all weaknesses and risks; prioritize by severity and likelihood |

### Expected Outputs

- Risk-prioritized list of concept weaknesses
- Edge-case scenarios with mitigation strategies
- User feedback from extreme user testing
- Ethical and reputational risk assessment
- Go/pivot/stop recommendation with supporting evidence

### Tips

- Explicitly reward finding problems; create psychological safety for critical feedback
- Invite at least one person who was not involved in creating the concept
- Bodystorming reveals physical and spatial issues that whiteboard reviews miss
- Use the Predict Next Year's Headlines output to brief leadership on risk

---

## 12. Post-Launch Learning Loop

**Duration**: 1 day | **Team Size**: 3-6 | **Format**: Hybrid

### Goal

After a product or feature has been live for 2-4 weeks, systematically learn from real usage data and user behavior. Bridges the gap between analytics dashboards and genuine user understanding, feeding insights back into the next iteration cycle.

### Method Sequence

| Time | Method | Category | Purpose |
|------|--------|----------|---------|
| 9:00-9:45 | Behavioral Archaeology | LOOK | Study real usage artifacts: support tickets, analytics patterns, user-generated content |
| 9:45-10:30 | Fly on the Wall | LOOK | Observe real users using the launched product in their natural context |
| 10:30-11:15 | Narration | ASK | Have users narrate their experience with the live product |
| 11:15-12:00 | Error Analysis | LEARN | Catalog actual errors, workarounds, and unexpected usage patterns |
| 13:00-13:45 | Five Whys | ASK | Drill into the top 3 unexpected behaviors or complaints |
| 13:45-14:30 | Activity Analysis | LEARN | Compare intended task flow vs. actual user behavior |
| 14:30-15:15 | Affinity Diagrams | LEARN | Cluster all findings into themes for the next iteration |
| 15:15-16:00 | Predict Next Year's Headlines | TRY | Project forward: what happens if these patterns continue or intensify |

### Expected Outputs

- Iteration backlog: prioritized list of improvements based on real usage
- Gap analysis: intended behavior vs. actual behavior
- Root cause analysis for top 3 user complaints
- Trend projection document for leadership review
- Updated character profiles reflecting real (not assumed) user segments

### Tips

- Wait at least 2 weeks post-launch; early data is noisy with novelty effects
- Cross-reference Behavioral Archaeology findings with analytics for triangulation
- Five Whys on support tickets often reveals systemic issues, not individual complaints
- Feed findings directly into sprint planning while the data is fresh
